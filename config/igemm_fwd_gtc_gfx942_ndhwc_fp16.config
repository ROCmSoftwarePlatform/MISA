[codegen]
arch = 'gfx942'
code_object = 'cov3'
mode = 'flat'

#########################################################################################
#--------------------------- 128x128x32
[igemm_fwd_gtc]
gemm_m_per_block         = 128
gemm_n_per_block         = 128
gemm_k_per_block         = 32
wave_tile_m              = 32
wave_step_m              = 1
wave_repeat_m            = 2
wave_tile_n              = 32
wave_step_n              = 1
wave_repeat_n            = 2
wave_tile_k              = 8
tensor_a_thread_lengths  = [1, 8, 2, 1]       # ExCxNB0xNB1
tensor_a_cluster_lengths = [1, 4, 1, 64]      # ExCxNB0xNB1
tensor_b_thread_lengths  = [1, 8, 2, 1]       # ExCxK0xK1
tensor_b_cluster_lengths = [1, 4, 1, 64]      # ExCxK0XK1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = 'ndhwc'
nxb                      = 0
nxe                      = 1

#--------------------------- 256x32x8, padded_c
[igemm_fwd_gtc]
gemm_m_per_block         = 256
gemm_n_per_block         = 32
gemm_k_per_block         = 8
wave_tile_m              = 64
wave_step_m              = 1
wave_repeat_m            = 2
wave_tile_n              = 16
wave_step_n              = 1
wave_repeat_n            = 1
wave_tile_k              = 4
tensor_a_thread_lengths  = [1, 1, 8, 1]       # ExCxNB0xNB1
tensor_a_cluster_lengths = [1, 8, 1, 32]      # ExCxNB0xNB1
tensor_b_thread_lengths  = [1, 1, 1, 1]       # ExCxK0xK1
tensor_b_cluster_lengths = [1, 8, 1, 32]      # ExCxK0XK1
direction                = "fwd"
precision                = "fp16"
tensor_layout            = 'ndhwc'
nxb                      = 0
nxe                      = 1
merge_e                  = 1
